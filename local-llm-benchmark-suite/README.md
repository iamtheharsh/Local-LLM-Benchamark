# Local LLM Benchmark Suite

A comprehensive testing interface for evaluating local Large Language Models (LLMs) performance, resource consumption, and capabilities on macOS.

## Overview

This application provides a three-panel interface for:
- **Chat Interface**: Test local LLMs with multimodal inputs
- **Agentic Capabilities**: Manage tools and MCP servers
- **RAG**: Manage vector databases and retrieval-augmented generation
- **Resource Monitoring**: Track RAM, CPU, and battery consumption
- **Event Logging**: Comprehensive operation logs with filtering

## Prerequisites

- Node.js (version 16 or higher)
- Rust (latest stable version)
- Xcode Command Line Tools (on macOS)

## Installation

1. Install dependencies:
```bash
npm install
```

2. Install Rust dependencies:
```bash
cd src-tauri
cargo build
cd ..
```

## Running the Application

### Development Mode

Start the development server:
```bash
npm run tauri dev
```

This will:
- Start the Vite development server on http://localhost:1420
- Launch the Tauri application window
- Enable hot reload for both frontend and backend

### Building for Production

Build the application:
```bash
npm run tauri build
```

This creates a distributable app in `src-tauri/target/release/bundle/`.

## Project Structure

```
local-llm-benchmark-suite/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatPanel.jsx          # Chat interface component
â”‚   â”‚   â”œâ”€â”€ AgenticPanel.jsx       # Agentic capabilities tab
â”‚   â”‚   â”œâ”€â”€ RAGPanel.jsx           # RAG management tab
â”‚   â”‚   â”œâ”€â”€ ToolsPanel.jsx         # Tools management tab
â”‚   â”‚   â””â”€â”€ MCPPanel.jsx           # MCP management tab
â”‚   â”œâ”€â”€ panels/
â”‚   â”‚   â”œâ”€â”€ ResourceMonitor.jsx    # Resource monitoring display
â”‚   â”‚   â””â”€â”€ LogsPanel.jsx          # Event logging display
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ metrics.js             # System metrics utilities
â”‚   â”‚   â””â”€â”€ logger.js              # Logging utility
â”‚   â”œâ”€â”€ App.jsx                    # Main application component
â”‚   â””â”€â”€ main.jsx                   # React entry point
â”œâ”€â”€ src-tauri/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ main.rs                # Rust backend entry point
â”‚   â”œâ”€â”€ Cargo.toml                 # Rust dependencies
â”‚   â””â”€â”€ build.rs                   # Build configuration
â”œâ”€â”€ tauri.conf.json                # Tauri configuration
â”œâ”€â”€ package.json                   # Node.js dependencies
â”œâ”€â”€ vite.config.js                 # Vite configuration
â””â”€â”€ index.html                     # HTML entry point
```

## Features

### Phase 1-7 âœ… COMPLETED
- âœ… Basic project structure
- âœ… Three-panel layout (Left: Tabs, Center: Resources, Right: Logs)
- âœ… Tab navigation system (Chat, Agentic, RAG, Tools, MCP)
- âœ… Dark theme UI with professional styling
- âœ… Modular component architecture

### Phase 2: Chat Interface âœ…
- âœ… Functional chat UI with message history
- âœ… Simulated LLM responses with latency tracking
- âœ… Token counting and metrics display
- âœ… Real-time thinking indicator
- âœ… Scroll-to-bottom and auto-scroll

### Phase 3: System Resources âœ…
- âœ… Live resource monitoring (RAM/CPU/Battery)
- âœ… Real-time metrics with threshold warnings
- âœ… Visual progress bars with color coding
- âœ… Polling system (1-second intervals)
- âœ… Tauri backend integration (with web fallback)

### Phase 4: Event Logging âœ…
- âœ… Comprehensive event logging system
- âœ… Multi-level logs (info, debug, warning, error)
- âœ… Category-based filtering
- âœ… Timestamps and log management
- âœ… Console integration with custom logger

### Phase 5: Tools Management âœ…
- âœ… Tool creation and editing interface
- âœ… HTTP tool configuration (GET, POST, PUT, DELETE)
- âœ… JSON schema validation for variables and headers
- âœ… Tool testing with latency measurement
- âœ… Response size and status tracking
- âœ… Enable/disable toggles

### Phase 6: RAG Panel âšª PLACEHOLDER
- âšª Coming in Phase 8+: RAG database management
- Vector database integration
- Document ingestion and indexing
- Retrieval-augmented generation testing

### Phase 7: MCP Integration âœ…
- âœ… MCP server management UI
- âœ… Server connection with latency measurement
- âœ… Tool discovery from connected servers
- âœ… Authentication token support
- âœ… Connect/disconnect functionality
- âœ… Simulated tool execution testing
- âœ… Integration hook for agentic pipelines

## Development

This project uses:
- **Tauri** for native desktop app framework
- **React** for UI components
- **Vite** for fast development and building
- **Rust** for backend operations

## Troubleshooting

### Issue: Permission denied when running `npm run tauri dev`
**Solution**: Make sure Xcode Command Line Tools are installed:
```bash
xcode-select --install
```

### Issue: Rust compilation errors
**Solution**: Update Rust to latest stable version:
```bash
rustup update stable
```

### Issue: Module not found errors
**Solution**: Clear node_modules and reinstall:
```bash
rm -rf node_modules package-lock.json
npm install
```

## License

MIT

## Contributing

This is a personal project for benchmarking local LLMs. Feel free to fork and modify for your needs.

## Current Status (November 2025)

### ðŸŽ‰ Phase 7 Complete: MCP Integration Layer

The Local LLM Benchmark Suite is now a comprehensive Apple Intelligence / Claude-style local agent framework with:

**âœ… Fully Implemented:**
- Multi-tab interface (Chat, Agentic, RAG, Tools, MCP)
- Real-time system resource monitoring
- Comprehensive event logging
- Tool management with HTTP API support
- MCP server connectivity and tool discovery
- Production-ready build system

**âšª Ready for Future Development:**
- Agentic Panel: Ready for agent workflow implementation
- RAG Panel: Ready for vector database integration
- Backend: Tauri/Rust backend for system metrics

**ðŸš€ Access the Application:**
```bash
# Development mode (with hot reload)
npm run dev

# Or run with Tauri
npm run tauri dev

# Build for production
npm run build
```

Visit http://localhost:1420/ to use the application.

**ðŸ“Š Architecture:**
The application is now a complete agent-ready platform that can:
- Connect to multiple MCP servers simultaneously
- Manage and test HTTP-based tools
- Monitor system resources in real-time
- Log all operations with comprehensive filtering
- Provide a foundation for agentic AI workflows

This positions the suite as a robust local alternative to cloud-based AI agents, with full control over data and resources.
